# -*- coding: utf-8 -*-
"""DT&RF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h8lGu7m6Pb3086u7BO7BI68tJ891JZHB
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix
from sklearn.tree import DecisionTreeClassifier
import graphviz
from sklearn import tree 

# wykorzystanie modeli drzew decyzyjnych oraz lasów losowych do rozpoznawania 10 cyfr pisanych odręcznie

digits = load_digits() # zdefiniowanie zbioru danych
plt.figure(1, figsize=(8, 8))
for i in range(10):
  plt.subplot(4,3,i+1)
  plt.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')
plt.show() # prezentacja 9 obiektów ze zbioru
 
X = digits.data # cechy
y = digits.target # zmienna zależna
X_train, X_test, y_train, y_test = train_test_split(X, y,
test_size=0.30, random_state=1)

clf = DecisionTreeClassifier() # obiekt klasyfikatora
clf = clf.fit(X_train,y_train) # trenowanie klasyfikatora

y_train_pred = clf.predict(X_train) # predykcja dla zbioru treningowego
print("Accuracy (train):", accuracy_score(y_train,y_train_pred)) # dokładność dla zbioru treningowego
 
y_pred = clf.predict(X_test) # predykcja dla zbioru testowego
print("Accuracy (test):", accuracy_score(y_test, y_pred)) # dokładność dla zbioru testowego
 
pcm = plot_confusion_matrix(clf, X_test, y_test)
plt.show()

dot_data = tree.export_graphviz(clf, out_file=None,
 filled=True, rotate=True,
 special_characters=True)
graph = graphviz.Source(dot_data, format='png')
graph.render('DTdigits10') # do pliku DTdiabetes.png
graph 

clf = DecisionTreeClassifier(criterion="entropy", max_depth=5)
clf = clf.fit(X_train,y_train) # trenowanie klasyfikatora

y_train_pred = clf.predict(X_train) # predykcja dla zbioru treningowego
print("Accuracy (train):", accuracy_score(y_train,y_train_pred)) # dokładność dla zbioru treningowego
 
y_pred = clf.predict(X_test) # predykcja dla zbioru testowego
print("Accuracy (test):", accuracy_score(y_test, y_pred)) # dokładność dla zbioru testowego
 
pcm = plot_confusion_matrix(clf, X_test, y_test)
plt.show()

dot_data = tree.export_graphviz(clf, out_file=None,
 filled=True, rotate=True,
 special_characters=True)
graph = graphviz.Source(dot_data, format='png')
graph.render('DTdigits5') # do pliku DTdiabetes.png
graph 

clf2 = RandomForestClassifier(n_estimators=10)
# obiekt klasyfikatora –liczba drzew = 10
clf2.fit(X_train, y_train) # trenowanie klasyfikatora
y_pred = clf2.predict(X_test)
print('\nAccuracy (test):', accuracy_score(y_test, y_pred)) # dokładność dla zbioru testowego
y_train_pred = clf2.predict(X_train)
print("Accuracy (train):", accuracy_score(y_train,y_train_pred)) # dokładność dla zbioru treningowego
 
classes = digits.target[clf2.predict(X_test)]
names = digits.target[y_test]
print('\n Confusion matrix')
print('\n', pd.crosstab(names, classes, rownames=['Actual'],
colnames=['Predicted']))
print(classification_report(y_test,y_pred))
 
print('\n')
importances = pd.Series(clf2.feature_importances_)
importances.nlargest(10).plot(kind='barh')
plt.xlabel('Relative Importance')
plt.show() # względna waga 10 najważniejszych cech
 
print('\nPredicted class probabilities')
print(clf.predict_proba(X_test[0:10])) # przewidziane prawdopodobieństwa dla 10 obiektów